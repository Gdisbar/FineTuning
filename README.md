# FineTuning
```
!jq 'del(.metadata.widgets)' Source.ipynb > Target.ipynb ## use this one in colab to avoid Github Metadata error
```
## Blogs

[Transformers](https://aigents.co/data-science-blog/publication/the-transformers-architecture-in-detail-whats-the-magic-behind-llms)

[Understanding LLM](https://magazine.sebastianraschka.com/p/understanding-large-language-models)

## YouTube


[Reproduce GPT-2](https://www.youtube.com/watch?v=l8pRSuU81PU)

[Reproduce Deepseek](https://www.youtube.com/playlist?list=PL0ioahleXcwvhkQ1z8ygRQI0EVg38Z0gf)

[AWS Sagemaker Deployment](https://www.youtube.com/watch?v=U72q95dHpRo)



## Github - AWS+GenAI

[GenAI+AWS](https://github.com/aws-samples/generative-ai-on-aws-immersion-day)


# GPU Training

[Gemma-2 9b 4-bit QLoRA fine-tuning](https://www.kaggle.com/code/emiz6413/training-gemma-2-9b-4-bit-qlora-fine-tuning)

# Training for custom application 

[Training Small Language Model](https://github.com/AIAnytime/Training-Small-Language-Model/blob/main/Training_a_Small_Language_Model.ipynb)

[Multi-label classification](https://www.kaggle.com/code/owaiskhan9654/multi-label-classification-of-pubmed-articles#-Training-the-model)

[Prompt Prediction - Miztral,Gemma,Llama](https://www.kaggle.com/code/aatiffraz/prompt-prediction-w-mixtral-mistral7b-gemma-llama)

[Code Interpreter Baseline](https://www.kaggle.com/code/huikang/code-interpreter-baseline)



