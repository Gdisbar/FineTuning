# FineTuning
```
!jq 'del(.metadata.widgets)' Source.ipynb > Target.ipynb ## use this one in colab to avoid Github Metadata error
```
## Blogs

[Transformers](https://aigents.co/data-science-blog/publication/the-transformers-architecture-in-detail-whats-the-magic-behind-llms)

[Understanding LLM](https://magazine.sebastianraschka.com/p/understanding-large-language-models)

## YouTube


[Reproduce GPT-2](https://www.youtube.com/watch?v=l8pRSuU81PU)

[Building Production RAG](https://www.youtube.com/watch?v=dI_TmTW9S4c)

[LangChain vs LangGraph](https://www.youtube.com/watch?v=bvMX-Zlfv68)

[DataStream with LangChain + FastAPI](https://www.youtube.com/watch?v=Gn54EbU9mRg)

[Build & Deploy AI ChatBot](https://www.youtube.com/watch?v=KyQKTJhSIak)

[Knowledge Graph](https://www.youtube.com/watch?app=desktop&v=yNCI3DC3tLg)

[RLHF - DPO](https://www.youtube.com/watch?app=desktop&v=aI8cyr-gH6M)

[AWS Sagemaker Deployment](https://www.youtube.com/watch?v=U72q95dHpRo)



## Github - AWS+GenAI
[GenAI+AWS](https://github.com/aws-samples/generative-ai-on-aws-immersion-day)



# LangChain,MLOps

[LangChain-FastAPI](https://github.com/Coding-Crashkurse/Advanced-LangChain-with-FastAPI)

[MLOps](https://github.com/olonok69/LLM_Notebooks/blob/main/mlflow/mlflow_transformers_fine_tuning.ipynb)


# GPU Training

[Gemma-2 9b 4-bit QLoRA fine-tuning](https://www.kaggle.com/code/emiz6413/training-gemma-2-9b-4-bit-qlora-fine-tuning)

# Fine-Tuning - deeplearning.ai

[Fine-tune FLAN-T5 with PPO](https://www.kaggle.com/code/paultimothymooney/fine-tune-flan-t5-with-ppo-deeplearning-ai)

# Training for custom application 

[Training Small Language Model](https://github.com/AIAnytime/Training-Small-Language-Model/blob/main/Training_a_Small_Language_Model.ipynb)

[Multi-label classification](https://www.kaggle.com/code/owaiskhan9654/multi-label-classification-of-pubmed-articles#-Training-the-model)

[Prompt Prediction - Miztral,Gemma,Llama](https://www.kaggle.com/code/aatiffraz/prompt-prediction-w-mixtral-mistral7b-gemma-llama)

[Code Interpreter Baseline](https://www.kaggle.com/code/huikang/code-interpreter-baseline)



